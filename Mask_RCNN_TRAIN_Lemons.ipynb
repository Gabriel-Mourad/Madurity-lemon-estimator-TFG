{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_RCNN_TRAIN_Lemons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEbDfY5R9as/iQcMX8rcQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabriel-Mourad/Madurity-lemon-estimator-TFG/blob/main/Mask_RCNN_TRAIN_Lemons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJymgA6Wn2jU",
        "outputId": "16229ed4-1b3f-441c-a08b-ae2f2f05ec40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/TFG"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/TFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "670e5A6uo0aU"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxQEfJd6kS2B"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3l1xCWXo6y3"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN\n",
        "%cd Mask_RCNN\n",
        "!pip3 install -3 requeriments.txt\n",
        "!python3 setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f2-30Cypvpk"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!make\n",
        "%cd ../../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJTRsmh1qJvn"
      },
      "source": [
        "import os \n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import imgaug\n",
        "\n",
        "\n",
        "\n",
        "# Directorio de trabajo\n",
        "ROOT_DIR = '/gdrive/MyDrive/TFG/projects/software/Mask_RCNN'\n",
        "\n",
        "\n",
        "sys.path.append(ROOT_DIR)\n",
        "\n",
        "# De la carpeta MRCNN importar:\n",
        "\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Directorio para guardar el modelo con la configuración interna:\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Directrorio del modelo inicial pre-entrenado:\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"logs/mask_rcnn_coco.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dgiQBCovseA"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZkUj2SwL57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7831f79-3eb4-425c-e178-3143819bf2fc"
      },
      "source": [
        "# Definición de los directorios de datos:\n",
        "\n",
        "DATA_DIR = \"/gdrive/MyDrive/TFG/projects/data\"\n",
        "\n",
        "DATASET_TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
        "DATASET_VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
        "DATASET_TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l4rZ7r0xg5f"
      },
      "source": [
        "CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3NX3ewcx92V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb8b305-80f8-44ef-b1f2-60c6c1261f61"
      },
      "source": [
        "# Configuración para el entrenamieto con el conjunto de datos de limones:\n",
        "\n",
        "class LemonsConfig( Config ):\n",
        "  \n",
        "  NAME = 'Lemons'\n",
        "  IMAGES_PER_GPU = 1\n",
        "  NUM_CLASSES = 1 + 1 + 1 + 1 # BACKGROUND + VERDE + MADURO + PODRIDO\n",
        "  STEPS_PER_EPOCH = 1950 #numero de fotos que hay en el train set\n",
        "  DETECTION_MIN_CONFIDENCE = 0.8\n",
        "\n",
        "config = LemonsConfig()\n",
        "config.display()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.8\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                16\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           Lemons\n",
            "NUM_CLASSES                    4\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1950\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRX8P4Axzn6u"
      },
      "source": [
        "from PIL import Image, ImageDraw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Z6T3Oszs_F"
      },
      "source": [
        "axis_Width = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDXsQ5eWz3YR"
      },
      "source": [
        "DATASET\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hOGEREW02nd"
      },
      "source": [
        "class LemonsDataset(utils.Dataset):\n",
        "    def load_dataset(self, dataset_dir):\n",
        "        self.add_class('dataset', 1, 'VERDE')\n",
        "        self.add_class('dataset', 2, 'MADURO')\n",
        "        self.add_class('dataset', 3, 'PODRIDO')        \n",
        "        # buscar todas las imagenes:\n",
        "        for i, filename in enumerate(os.listdir(dataset_dir)):\n",
        "            annotation_file = os.path.join(dataset_dir, filename.replace('.jpg', '.json'))\n",
        "            if '.jpg' in filename and os.path.isfile(annotation_file):\n",
        "                    self.add_image('dataset',\n",
        "                               image_id=i,\n",
        "                               path=os.path.join(dataset_dir, filename),\n",
        "                               annotation=annotation_file)\n",
        "   \n",
        "# extracción de mascaras a cada imagen:\n",
        "    def extract_masks(self, filename):\n",
        "        json_file = os.path.join(filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "       \n",
        "        n_masks = 0\n",
        "        for anno in img_anns['shapes']:\n",
        "            if anno['label']=='VERDE' or anno['label']=='MADURO' or anno['label']=='PODRIDO':\n",
        "                n_masks+=1\n",
        "           \n",
        "        masks = np.zeros([img_anns['imageHeight'], img_anns['imageWidth'], n_masks], dtype='uint8')\n",
        "        classes = []\n",
        "        i=0\n",
        "        for anno in img_anns['shapes']:\n",
        "            if anno['label']=='VERDE' or anno['label']=='MADURO' or anno['label']=='PODRIDO':\n",
        "                mask = np.zeros([img_anns['imageHeight'], img_anns['imageWidth']], dtype=np.uint8)            \n",
        "                cv2.fillPoly(mask, np.array([anno['points']], dtype=np.int32), 1)\n",
        "                masks[:, :, i] = mask\n",
        "                classes.append(self.class_names.index(anno['label']))\n",
        "                i+=1\n",
        "        return masks, classes\n",
        "   \n",
        "\n",
        "    # lcargar las máscaras\n",
        "    def load_mask(self, image_id):\n",
        "        # get details of image\n",
        "        info = self.image_info[image_id]\n",
        "        # define box file location\n",
        "        path = info['annotation']\n",
        "        # load masks\n",
        "        masks, classes = self.extract_masks(path)\n",
        "        return masks, np.asarray(classes, dtype='int32')\n",
        "   \n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TXW5FZE53Cn"
      },
      "source": [
        "1 executar codi # create\n",
        "2 executar codi content/drive\n",
        "3 tornar a executar codi #create"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2KupPQt6QGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c5911d-7950-49ca-a50e-d54074f2dd25"
      },
      "source": [
        "# CREACION DEL DATASET\n",
        "\n",
        "# train set\n",
        "\n",
        "dataset_train = LemonsDataset()\n",
        "dataset_train.load_dataset(DATASET_TRAIN_DIR)\n",
        "dataset_train.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset_train.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset_train.num_classes))\n",
        "for i, info in enumerate(dataset_train.class_info):\n",
        "  print(\"{:3}.  {:50}\".format(i, info['name']))\n",
        "\n",
        "# test set\n",
        "\n",
        "dataset_test = LemonsDataset()\n",
        "dataset_test.load_dataset(DATASET_TEST_DIR)\n",
        "dataset_test.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset_test.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset_test.num_classes))\n",
        "for i, info in enumerate(dataset_test.class_info):\n",
        "  print(\"{:3}.  {:50}\".format(i, info['name']))\n",
        "\n",
        "# val set\n",
        "\n",
        "dataset_val = LemonsDataset()\n",
        "dataset_val.load_dataset(DATASET_VAL_DIR)\n",
        "dataset_val.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset_val.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset_val.num_classes))\n",
        "for i, info in enumerate(dataset_val.class_info):\n",
        "  print(\"{:3}.  {:50}\".format(i, info['name']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Count: 1950\n",
            "Class Count: 4\n",
            "  0.  BG                                                \n",
            "  1.  VERDE                                             \n",
            "  2.  MADURO                                            \n",
            "  3.  PODRIDO                                           \n",
            "Image Count: 557\n",
            "Class Count: 4\n",
            "  0.  BG                                                \n",
            "  1.  VERDE                                             \n",
            "  2.  MADURO                                            \n",
            "  3.  PODRIDO                                           \n",
            "Image Count: 278\n",
            "Class Count: 4\n",
            "  0.  BG                                                \n",
            "  1.  VERDE                                             \n",
            "  2.  MADURO                                            \n",
            "  3.  PODRIDO                                           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPa2AUWG9nJ6"
      },
      "source": [
        "image_ids = np.random.choice(dataset_train.image_ids, 5)\n",
        "for image_id in image_ids:\n",
        "  image = dataset_train.load_image(image_id)\n",
        "  mask, class_ids = dataset_train.load_mask(image_id)\n",
        "  visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQdAwPJyMFo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799d4470-05a5-4474-f6c5-935963cbb7a0"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53DIcc0zOqUz"
      },
      "source": [
        "# Creación del modelo: seleccionar modo, configuración y directorio de trabajo\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNJTR2EtZ3CU",
        "outputId": "5fe0afad-4ef8-4bb3-aa2a-31d6d73c90b7"
      },
      "source": [
        "print(model.find_last())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/TFG/projects/software/Mask_RCNN/logs/lemons20210608T0829/mask_rcnn_lemons_0009.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2PRHamNpzSm"
      },
      "source": [
        "%tensorboard --logdir /gdrive/MyDrive/TFG/projects/software/Mask_RCNN/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsMNX9IrO8n1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1542e744-a0f4-4508-dc6f-fb6d323c8eec"
      },
      "source": [
        "# Cargar la configuración de pesos del modelo:\n",
        "\n",
        "init_with = \"last\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "   \n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Cargar el ultimo modelo entrnado y continuar con el entrenamiento\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Re-starting from epoch 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F1M-sF5qzlz"
      },
      "source": [
        "TRAIN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPKsOgK_oxcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4462cdd1-292a-4279-b340-43603c218da8"
      },
      "source": [
        "Lemon_augmentation = imgaug.augmenters.Sometimes(0.5,\n",
        "    [imgaug.augmenters.geometric.Affine(rotate=(-360,360))])\n",
        "    \n",
        "    \n",
        "model.train(dataset_train, dataset_test, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=100,\n",
        "            layers='heads',augmentation = Lemon_augmentation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 9. LR=0.001\n",
            "\n",
            "Checkpoint Path: /gdrive/MyDrive/TFG/projects/software/Mask_RCNN/logs/lemons20210608T0829/mask_rcnn_lemons_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/100\n",
            "1950/1950 [==============================] - 1114s 571ms/step - loss: 0.1160 - val_loss: 0.0692\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 11/100\n",
            "1950/1950 [==============================] - 1033s 530ms/step - loss: 0.1104 - val_loss: 0.0526\n",
            "Epoch 12/100\n",
            "1950/1950 [==============================] - 746s 383ms/step - loss: 0.0920 - val_loss: 0.0266\n",
            "Epoch 13/100\n",
            "1950/1950 [==============================] - 693s 356ms/step - loss: 0.0808 - val_loss: 0.0345\n",
            "Epoch 14/100\n",
            "1950/1950 [==============================] - 737s 378ms/step - loss: 0.0780 - val_loss: 0.0533\n",
            "Epoch 15/100\n",
            "1950/1950 [==============================] - 741s 380ms/step - loss: 0.0784 - val_loss: 0.0336\n",
            "Epoch 16/100\n",
            "1950/1950 [==============================] - 765s 392ms/step - loss: 0.0805 - val_loss: 0.0392\n",
            "Epoch 17/100\n",
            "1950/1950 [==============================] - 729s 374ms/step - loss: 0.0712 - val_loss: 0.0298\n",
            "Epoch 18/100\n",
            "1950/1950 [==============================] - 797s 409ms/step - loss: 0.0779 - val_loss: 0.0531\n",
            "Epoch 19/100\n",
            "1950/1950 [==============================] - 728s 373ms/step - loss: 0.0666 - val_loss: 0.0352\n",
            "Epoch 20/100\n",
            "1950/1950 [==============================] - 785s 402ms/step - loss: 0.0733 - val_loss: 0.0273\n",
            "Epoch 21/100\n",
            "1950/1950 [==============================] - 792s 406ms/step - loss: 0.0653 - val_loss: 0.0370\n",
            "Epoch 22/100\n",
            "1950/1950 [==============================] - 762s 391ms/step - loss: 0.0663 - val_loss: 0.0421\n",
            "Epoch 23/100\n",
            "1950/1950 [==============================] - 782s 401ms/step - loss: 0.0695 - val_loss: 0.0474\n",
            "Epoch 24/100\n",
            "1950/1950 [==============================] - 758s 389ms/step - loss: 0.0700 - val_loss: 0.0696\n",
            "Epoch 25/100\n",
            "1950/1950 [==============================] - 764s 392ms/step - loss: 0.0649 - val_loss: 0.0355\n",
            "Epoch 26/100\n",
            "1950/1950 [==============================] - 763s 391ms/step - loss: 0.0621 - val_loss: 0.0332\n",
            "Epoch 27/100\n",
            "1950/1950 [==============================] - 770s 395ms/step - loss: 0.0691 - val_loss: 0.0361\n",
            "Epoch 28/100\n",
            "1950/1950 [==============================] - 760s 390ms/step - loss: 0.0642 - val_loss: 0.2089\n",
            "Epoch 29/100\n",
            "1950/1950 [==============================] - 776s 398ms/step - loss: 0.0699 - val_loss: 0.0340\n",
            "Epoch 30/100\n",
            "1950/1950 [==============================] - 764s 392ms/step - loss: 0.0666 - val_loss: 0.0295\n",
            "Epoch 31/100\n",
            "1950/1950 [==============================] - 778s 399ms/step - loss: 0.0640 - val_loss: 0.0428\n",
            "Epoch 32/100\n",
            "1950/1950 [==============================] - 807s 414ms/step - loss: 0.0680 - val_loss: 0.0327\n",
            "Epoch 33/100\n",
            "1950/1950 [==============================] - 818s 419ms/step - loss: 0.0671 - val_loss: 0.0397\n",
            "Epoch 34/100\n",
            "1950/1950 [==============================] - 809s 415ms/step - loss: 0.0650 - val_loss: 0.8757\n",
            "Epoch 35/100\n",
            "1950/1950 [==============================] - 757s 388ms/step - loss: 0.0607 - val_loss: 0.0300\n",
            "Epoch 36/100\n",
            "1950/1950 [==============================] - 784s 402ms/step - loss: 0.0663 - val_loss: 0.0392\n",
            "Epoch 37/100\n",
            "1950/1950 [==============================] - 783s 401ms/step - loss: 0.0576 - val_loss: 0.0308\n",
            "Epoch 38/100\n",
            "1950/1950 [==============================] - 780s 400ms/step - loss: 0.0567 - val_loss: 0.0452\n",
            "Epoch 39/100\n",
            "1950/1950 [==============================] - 857s 440ms/step - loss: 0.0670 - val_loss: 0.0241\n",
            "Epoch 40/100\n",
            "1950/1950 [==============================] - 820s 421ms/step - loss: 0.0663 - val_loss: 0.0441\n",
            "Epoch 41/100\n",
            "1950/1950 [==============================] - 742s 381ms/step - loss: 0.0537 - val_loss: 0.0362\n",
            "Epoch 42/100\n",
            "1950/1950 [==============================] - 803s 412ms/step - loss: 0.0642 - val_loss: 0.0333\n",
            "Epoch 43/100\n",
            "1950/1950 [==============================] - 814s 418ms/step - loss: 0.0625 - val_loss: 0.1578\n",
            "Epoch 44/100\n",
            "1950/1950 [==============================] - 771s 395ms/step - loss: 0.0567 - val_loss: 0.0605\n",
            "Epoch 45/100\n",
            "1950/1950 [==============================] - 782s 401ms/step - loss: 0.0596 - val_loss: 0.0434\n",
            "Epoch 46/100\n",
            "1950/1950 [==============================] - 842s 432ms/step - loss: 0.0599 - val_loss: 0.0634\n",
            "Epoch 47/100\n",
            "1950/1950 [==============================] - 788s 404ms/step - loss: 0.0620 - val_loss: 0.0385\n",
            "Epoch 48/100\n",
            "1950/1950 [==============================] - 740s 379ms/step - loss: 0.0591 - val_loss: 0.0600\n",
            "Epoch 49/100\n",
            "1950/1950 [==============================] - 803s 412ms/step - loss: 0.0605 - val_loss: 0.0476\n",
            "Epoch 50/100\n",
            "1950/1950 [==============================] - 830s 426ms/step - loss: 0.0619 - val_loss: 0.0357\n",
            "Epoch 51/100\n",
            "1950/1950 [==============================] - 776s 398ms/step - loss: 0.0595 - val_loss: 0.0610\n",
            "Epoch 52/100\n",
            "1950/1950 [==============================] - 770s 395ms/step - loss: 0.0623 - val_loss: 0.0323\n",
            "Epoch 53/100\n",
            "1950/1950 [==============================] - 775s 398ms/step - loss: 0.0588 - val_loss: 0.0206\n",
            "Epoch 54/100\n",
            "1950/1950 [==============================] - 749s 384ms/step - loss: 0.0524 - val_loss: 0.0586\n",
            "Epoch 55/100\n",
            "1950/1950 [==============================] - 851s 436ms/step - loss: 0.0586 - val_loss: 0.9634\n",
            "Epoch 56/100\n",
            "1950/1950 [==============================] - 806s 413ms/step - loss: 0.0571 - val_loss: 0.0618\n",
            "Epoch 57/100\n",
            "1950/1950 [==============================] - 741s 380ms/step - loss: 0.0534 - val_loss: 0.0635\n",
            "Epoch 58/100\n",
            "1950/1950 [==============================] - 793s 407ms/step - loss: 0.0569 - val_loss: 0.0255\n",
            "Epoch 59/100\n",
            "1950/1950 [==============================] - 808s 414ms/step - loss: 0.0563 - val_loss: 0.0366\n",
            "Epoch 60/100\n",
            "1950/1950 [==============================] - 761s 390ms/step - loss: 0.0536 - val_loss: 0.0311\n",
            "Epoch 61/100\n",
            "1950/1950 [==============================] - 802s 411ms/step - loss: 0.0561 - val_loss: 0.0220\n",
            "Epoch 62/100\n",
            "1950/1950 [==============================] - 864s 443ms/step - loss: 0.0567 - val_loss: 0.0268\n",
            "Epoch 63/100\n",
            "1950/1950 [==============================] - 811s 416ms/step - loss: 0.0512 - val_loss: 0.1398\n",
            "Epoch 64/100\n",
            "1950/1950 [==============================] - 768s 394ms/step - loss: 0.0538 - val_loss: 0.0233\n",
            "Epoch 65/100\n",
            "1950/1950 [==============================] - 796s 408ms/step - loss: 0.0562 - val_loss: 0.0378\n",
            "Epoch 66/100\n",
            "1950/1950 [==============================] - 810s 415ms/step - loss: 0.0577 - val_loss: 0.0384\n",
            "Epoch 67/100\n",
            "1950/1950 [==============================] - 763s 391ms/step - loss: 0.0531 - val_loss: 0.0324\n",
            "Epoch 68/100\n",
            "1950/1950 [==============================] - 791s 406ms/step - loss: 0.0594 - val_loss: 0.0190\n",
            "Epoch 69/100\n",
            "1950/1950 [==============================] - 765s 392ms/step - loss: 0.0535 - val_loss: 0.0379\n",
            "Epoch 70/100\n",
            "1950/1950 [==============================] - 865s 444ms/step - loss: 0.0535 - val_loss: 0.0778\n",
            "Epoch 71/100\n",
            "1950/1950 [==============================] - 819s 420ms/step - loss: 0.0549 - val_loss: 0.0193\n",
            "Epoch 72/100\n",
            "1950/1950 [==============================] - 873s 448ms/step - loss: 0.0577 - val_loss: 0.0618\n",
            "Epoch 73/100\n",
            "1950/1950 [==============================] - 806s 413ms/step - loss: 0.0505 - val_loss: 0.0298\n",
            "Epoch 74/100\n",
            "1950/1950 [==============================] - 789s 405ms/step - loss: 0.0569 - val_loss: 0.0270\n",
            "Epoch 75/100\n",
            "1950/1950 [==============================] - 749s 384ms/step - loss: 0.0508 - val_loss: 0.5857\n",
            "Epoch 76/100\n",
            "1950/1950 [==============================] - 739s 379ms/step - loss: 0.0470 - val_loss: 0.0325\n",
            "Epoch 77/100\n",
            "1950/1950 [==============================] - 828s 425ms/step - loss: 0.0589 - val_loss: 0.0535\n",
            "Epoch 78/100\n",
            "1950/1950 [==============================] - 846s 434ms/step - loss: 0.0518 - val_loss: 0.3362\n",
            "Epoch 79/100\n",
            "1950/1950 [==============================] - 851s 436ms/step - loss: 0.0507 - val_loss: 0.0318\n",
            "Epoch 80/100\n",
            "1950/1950 [==============================] - 880s 451ms/step - loss: 0.0504 - val_loss: 0.0204\n",
            "Epoch 81/100\n",
            "1950/1950 [==============================] - 828s 424ms/step - loss: 0.0527 - val_loss: 0.0222\n",
            "Epoch 82/100\n",
            "1950/1950 [==============================] - 784s 402ms/step - loss: 0.0483 - val_loss: 0.0199\n",
            "Epoch 83/100\n",
            "1950/1950 [==============================] - 788s 404ms/step - loss: 0.0483 - val_loss: 0.0222\n",
            "Epoch 84/100\n",
            "1950/1950 [==============================] - 784s 402ms/step - loss: 0.0516 - val_loss: 0.0355\n",
            "Epoch 85/100\n",
            "1950/1950 [==============================] - 876s 449ms/step - loss: 0.0569 - val_loss: 0.2418\n",
            "Epoch 86/100\n",
            "1950/1950 [==============================] - 800s 410ms/step - loss: 0.0514 - val_loss: 0.0198\n",
            "Epoch 87/100\n",
            "1950/1950 [==============================] - 813s 417ms/step - loss: 0.0482 - val_loss: 0.0455\n",
            "Epoch 88/100\n",
            "1950/1950 [==============================] - 869s 445ms/step - loss: 0.0531 - val_loss: 0.0276\n",
            "Epoch 89/100\n",
            "1950/1950 [==============================] - 809s 415ms/step - loss: 0.0464 - val_loss: 0.0956\n",
            "Epoch 90/100\n",
            "1950/1950 [==============================] - 798s 409ms/step - loss: 0.0476 - val_loss: 0.0347\n",
            "Epoch 91/100\n",
            "1950/1950 [==============================] - 829s 425ms/step - loss: 0.0557 - val_loss: 0.0372\n",
            "Epoch 92/100\n",
            "1950/1950 [==============================] - 866s 444ms/step - loss: 0.0533 - val_loss: 0.0773\n",
            "Epoch 93/100\n",
            "1950/1950 [==============================] - 810s 415ms/step - loss: 0.0504 - val_loss: 0.0241\n",
            "Epoch 94/100\n",
            "1950/1950 [==============================] - 809s 415ms/step - loss: 0.0524 - val_loss: 0.0360\n",
            "Epoch 95/100\n",
            "1950/1950 [==============================] - 782s 401ms/step - loss: 0.0511 - val_loss: 0.0234\n",
            "Epoch 96/100\n",
            "1950/1950 [==============================] - 834s 428ms/step - loss: 0.0506 - val_loss: 0.0350\n",
            "Epoch 97/100\n",
            "1950/1950 [==============================] - 819s 420ms/step - loss: 0.0472 - val_loss: 0.0288\n",
            "Epoch 98/100\n",
            "1950/1950 [==============================] - 847s 435ms/step - loss: 0.0533 - val_loss: 0.0524\n",
            "Epoch 99/100\n",
            "1950/1950 [==============================] - 849s 436ms/step - loss: 0.0523 - val_loss: 0.0320\n",
            "Epoch 100/100\n",
            "1950/1950 [==============================] - 812s 416ms/step - loss: 0.0483 - val_loss: 0.0345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOVZDuZlqqSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a68dc0c-cd22-4385-eec0-f35e9c0ea946"
      },
      "source": [
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=10, \n",
        "            layers=\"all\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 100. LR=0.0001\n",
            "\n",
            "Checkpoint Path: /gdrive/MyDrive/TFG/projects/software/Mask_RCNN/logs/lemons20210608T0829/mask_rcnn_lemons_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}